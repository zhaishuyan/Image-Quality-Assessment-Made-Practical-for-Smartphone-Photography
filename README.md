# Image-Quality-Assessment-Made-Practical-for-Smartphone-Photography

[![Academic Use Only](https://img.shields.io/badge/License-Academic%20Only-blue.svg)](LICENSE)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?logo=PyTorch&logoColor=white)](https://pytorch.org/)


> A practical No-Reference Image Quality Assessment (NR-IQA) method specifically designed for modern smartphone photography challenges. Trained on real-world smartphone images with subjective labels.

## Introduction

We establish the relationships among quality labels by constructing a HEX graph informed by prior knowledge. Based on this framework, we propose a probabilistic multi-label ordinal regression model formulated as a conditional random field (CRF).

## Project Progress Tracker

### âœ… Completed Milestones

- Constructed a 6-label HEX graph for initial validation

```
Labels = [ æ•´ä½“åäº®, æ•´ä½“åæš—, æ•´ä½“å¯¹æ¯”åº¦é«˜, æ•´ä½“å¯¹æ¯”åº¦ä½, é«˜å…‰è¿‡æ›, é«˜å…‰å‹åˆ¶è¿‡åº¦]
Levels = { "0": "ä¸å­˜åœ¨ç›¸åº”é—®é¢˜", "1": "æ™®é€š", "2": "ä¸¥é‡", "3": "é˜»å¡"}
Nodes = [
    {"label":"æ•´ä½“åäº®","levels":[1,2,3,4]},
    {"label":"æ•´ä½“åæš—","levels":[1,2,3,4]},
    {"label":"æ•´ä½“å¯¹æ¯”åº¦é«˜","levels":[1,2,3,4]},
    {"label":"æ•´ä½“å¯¹æ¯”åº¦ä½","levels":[1,2,3,4]},
    {"label":"é«˜å…‰è¿‡æ›","levels":[1,2,3,4]},
    {"label":"é«˜å…‰å‹åˆ¶è¿‡åº¦","levels":[1,2,3,4]}
  ]
Exclusions = [
		# undirected edges
    {"label_a":"æ•´ä½“åäº®","a_levels":[2,3,4], "label_b":"æ•´ä½“åæš—","b_levels":[2,3,4]},
    {"label_a":"æ•´ä½“å¯¹æ¯”åº¦é«˜","a_levels":[2,3,4], "label_b":"æ•´ä½“å¯¹æ¯”åº¦ä½","b_levels":[2,3,4]},
    {"label_a":"é«˜å…‰è¿‡æ›","a_levels":[2,3,4], "label_b":"é«˜å…‰å‹åˆ¶è¿‡åº¦","b_levels":[2,3,4]}
]
Subsumptions = [
		# directed edges
    {"label_a":"æ•´ä½“åäº®", "label_b":"æ•´ä½“åæš—", "map":[[1,1]]},
    {"label_a":"æ•´ä½“å¯¹æ¯”åº¦é«˜"ï¼Œ"label_b":"æ•´ä½“å¯¹æ¯”åº¦ä½", "map":[[1,1]]},
    {"label_a":"é«˜å…‰è¿‡æ›"ï¼Œ"label_b":"é«˜å…‰å‹åˆ¶è¿‡åº¦", "map":[[1,1]]}
]
```
  
- Prepared data with the six labels

| Dataset    | Total | Has Issue | No Issue | bright | dark | low_contrast | high_contrast | overexposed | over_suppressed |
|------------|-------|-----------|----------|--------|------|--------------|---------------|-------------|-----------------|
| Overall    | 2342  | 400       | 1942     | 78     | 146  | 53           | 73            | 21          | 34              |
| Train      | 1638  | 278       | 1360     | 56     | 97   | 40           | 57            | 13          | 19              |
| Validation | 352   | 65        | 287      | 7      | 27   | 9            | 8             | 7           | 8               |
| Test       | 352   | 58        | 294      | 12     | 22   | 8            | 11            | 3           | 5               |
  
- Implemented code using CLIP as the base model

  - CLIP image encoder
 
  - HEX graph loss


### ğŸ”„ In Progress

### ğŸ”œ Next Steps
